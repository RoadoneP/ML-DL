{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BackPropagation for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(([2, 9],[1, 5],[3, 6]), dtype=float)\n",
    "y = np.array(([92], [86], [89]), dtype=float)\n",
    "\n",
    "\n",
    "#scale units\n",
    "X = X/np.amax(X, axis=0)\n",
    "y = y/100\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 0\n",
      "W1: [[ 0.16378345 -1.52921817 -0.81486972]\n",
      " [-1.89636328  0.28393838  0.4088111 ]]\n",
      "W2: [[0.5498323 ]\n",
      " [0.49947428]\n",
      " [1.53372711]]\n",
      "output: [[0.7223344 ]\n",
      " [0.75101272]\n",
      " [0.69099784]]\n",
      "Loss :0.03018392632929497\n",
      "\n",
      "\n",
      "number 100\n",
      "W1: [[ 0.32836051 -1.3388771  -0.21054664]\n",
      " [-1.74961692  0.47679715  0.9911113 ]]\n",
      "W2: [[0.88085727]\n",
      " [0.93963432]\n",
      " [2.33613215]]\n",
      "output: [[0.89726582]\n",
      " [0.89398839]\n",
      " [0.87451204]]\n",
      "Loss :0.0006373101104586054\n",
      "\n",
      "\n",
      "number 200\n",
      "W1: [[ 0.34807049 -1.31316204 -0.14013853]\n",
      " [-1.74321994  0.49170301  1.027441  ]]\n",
      "W2: [[0.85549387]\n",
      " [0.89849749]\n",
      " [2.3430983 ]]\n",
      "output: [[0.90032335]\n",
      " [0.8947121 ]\n",
      " [0.87973461]]\n",
      "Loss :0.0005658263765991814\n",
      "\n",
      "\n",
      "number 300\n",
      "W1: [[ 0.36194402 -1.29401379 -0.08911855]\n",
      " [-1.74057291  0.50194376  1.04912632]]\n",
      "W2: [[0.82247957]\n",
      " [0.85036769]\n",
      " [2.33262564]]\n",
      "output: [[0.90024982]\n",
      " [0.89289323]\n",
      " [0.88104674]]\n",
      "Loss :0.000517398354254277\n",
      "\n",
      "\n",
      "number 400\n",
      "W1: [[ 0.37414245 -1.27659192 -0.0438861 ]\n",
      " [-1.73791651  0.51227727  1.0690255 ]]\n",
      "W2: [[0.78995351]\n",
      " [0.80585976]\n",
      " [2.32457195]]\n",
      "output: [[0.90008749]\n",
      " [0.89114294]\n",
      " [0.88202968]]\n",
      "Loss :0.0004766389351150738\n",
      "\n",
      "\n",
      "number 500\n",
      "W1: [[ 0.38504929 -1.26051852 -0.00313282]\n",
      " [-1.73511926  0.52276117  1.08781438]]\n",
      "W2: [[0.75829976]\n",
      " [0.76513367]\n",
      " [2.31948579]]\n",
      "output: [[0.89998935]\n",
      " [0.88958197]\n",
      " [0.88289642]]\n",
      "Loss :0.00044199323168011575\n",
      "\n",
      "\n",
      "number 600\n",
      "W1: [[ 0.39482139 -1.24566444  0.03370714]\n",
      " [-1.73223518  0.53325046  1.10553304]]\n",
      "W2: [[0.72746201]\n",
      " [0.72779132]\n",
      " [2.31688939]]\n",
      "output: [[0.89994918]\n",
      " [0.8881904 ]\n",
      " [0.88367003]]\n",
      "Loss :0.0004122674901462935\n",
      "\n",
      "\n",
      "number 700\n",
      "W1: [[ 0.40358666 -1.23192113  0.06709809]\n",
      " [-1.72931523  0.54363095  1.12221291]]\n",
      "W2: [[0.69736808]\n",
      " [0.69345303]\n",
      " [2.3163363 ]]\n",
      "output: [[0.89995486]\n",
      " [0.88694407]\n",
      " [0.88436158]]\n",
      "Loss :0.0003865274310022259\n",
      "\n",
      "\n",
      "number 800\n",
      "W1: [[ 0.41145689 -1.21918881  0.09744389]\n",
      " [-1.72639933  0.55382171  1.13790084]]\n",
      "W2: [[0.66795459]\n",
      " [0.66178667]\n",
      " [2.31745893]]\n",
      "output: [[0.8999966 ]\n",
      " [0.88582224]\n",
      " [0.88498044]]\n",
      "Loss :0.0003640400302788326\n",
      "\n",
      "\n",
      "number 900\n",
      "W1: [[ 0.4185302  -1.20737615  0.1250959 ]\n",
      " [-1.72351834  0.56376708  1.15265268]]\n",
      "W2: [[0.63916731]\n",
      " [0.63250348]\n",
      " [2.31995728]]\n",
      "output: [[0.90006678]\n",
      " [0.88480751]\n",
      " [0.88553493]]\n",
      "Loss :0.00034422750786920335\n",
      "\n",
      "\n",
      "Input[[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output: [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Loss: 0.00032663184949604054\n",
      "\n",
      "\n",
      "Predicted Output: [[0.90015948]\n",
      " [0.8838853 ]\n",
      " [0.88603239]]\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        #parameters\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        \n",
    "        self.W1 = np.random.randn(self.inputSize, self.hiddenSize) #2*3 \n",
    "        self.W2 = np.random.randn(self.hiddenSize, self.outputSize) #3*1\n",
    "        \n",
    "    def Forward(self, X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        output = self.sigmoid(self.z3)\n",
    "        return output\n",
    "    \n",
    "    def sigmoid(self, s, deriv=False):\n",
    "        if(deriv == True):\n",
    "            return s * (1 - s)\n",
    "        return 1/(1+ np. exp(-s))\n",
    "    \n",
    "    def backward(self, X, y, output):\n",
    "        self.output_error = y - output\n",
    "        self.output_delta = self.output_error * self.sigmoid(output, deriv=True)\n",
    "        \n",
    "        self.z2_error = self.output_delta.dot(self.W2.T)\n",
    "        self.z2_delta = self.z2_error * self.sigmoid(self.z2, deriv=True)\n",
    "        \n",
    "        self.W1 += X.T.dot(self.z2_delta)\n",
    "        self.W2 += self.z2.T.dot(self.output_delta)\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        output = self.Forward(X)\n",
    "        self.backward(X, y, output)\n",
    "        \n",
    "NN = NeuralNetwork()\n",
    "\n",
    "for i in range(1000):\n",
    "    if(i % 100 == 0):\n",
    "        print(\"number\",i)\n",
    "        print(\"W1: \" + str(NN.W1))\n",
    "        print(\"W2: \" + str(NN.W2))\n",
    "        print(\"output: \" + str(NN.Forward(X)))\n",
    "        print(\"Loss :\" + str(np.mean(np.square(y - NN.Forward(X)))))\n",
    "        print(\"\\n\")\n",
    "    NN.train(X, y)\n",
    "    \n",
    "print(\"Input\" + str(X))\n",
    "print(\"Actual Output: \" + str(y))\n",
    "print(\"Loss: \" + str(np.mean(np.square(y - NN.Forward(X)))))\n",
    "print(\"\\n\")\n",
    "print(\"Predicted Output: \" + str(NN.Forward(X))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
